import keras
from keras.models import Sequential
from keras.layers import Flatten, Dense, Lambda, Dropout
from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense


# input the number of classes for the final layer (number of labels)
num_class = 36


def create_model(X_train, num_class, showSummary = False ):
    
    model = Sequential()
    # adds a 2-d convolution neural network of 32 nodes wit 5x5 kernal size
    model.add(Conv2D(32, (5, 5), input_shape=X_train[0].shape))
    # activation function used in between layers except the final layer is relu function 
    model.add(Activation('relu'))       
    model.add(MaxPooling2D(pool_size=(2,2)))

    model.add(Conv2D(64, (5, 5)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))

    model.add(Conv2D(96, (3, 3)))
    model.add(Activation('relu'))
   
    model.add(MaxPooling2D(pool_size=(2,2)))

    # model.add(Conv2D(120, (2, 2)))
    # model.add(Activation('relu'))
    # model.add(MaxPooling2D(pool_size=(2,2)))  

    model.add(Flatten())        

    model.add(Dense(1024))
    model.add(Activation('relu'))  


    # model.add(MaxPooling2D(pool_size=(2,2)))  
    # model.add(Flatten())
    # model.add(Dropout(0.2))

    model.add(Dense(num_class))
    model.add(Activation('softmax'))

    if(showSummary == True):
        model.summary()
        
    return model
    
model = create_model(X_train, num_class)
